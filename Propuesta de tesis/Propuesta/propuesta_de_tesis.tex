\documentclass[12pt]{article}

%pdflatex -interaction=nonstopmode %.tex|biber %|pdflatex -interaction=nonstopmode %.tex|pdflatex -synctex=1 -interaction=nonstopmode %.tex|evince %.pdf
\usepackage[isbn=false,doi=false,url=false,eprint=false,backend=biber,style=numeric,sorting=none,maxbibnames=3]{biblatex}
\addbibresource{mybib.bib}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[polish,spanish]{babel}
%\usepackage[english]{babel}
\usepackage[latin5]{inputenc}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage[left=3cm,top=3cm,right=3cm,nohead,nofoot]{geometry}
\usepackage{braket}
\usepackage{quotmark}
\usepackage{csquotes}
\usepackage{datenumber}
\usepackage{aas_macros}
%\usepackage{natbib}
%\newdate{date}{10}{05}{2013}
%\date{\displaydate{date}}

%page style
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}%really no need for a ruler
%\fancyfoot[C]{\thepage}


\DeclareLanguageMapping{spanish}{spanish-lat}
\begin{document}
\selectlanguage{spanish}
\pagebreak
\pagestyle{empty}
\begin{center}
\Huge
Búsqueda de estrellas variables extragalácticas usando algoritmos de Machine Learning

\vspace{3mm}
\Large Javier Alejandro Acevedo Barroso

\large
201422995


\vspace{2mm}
\Large
Director: Alejandro García

\normalsize
\vspace{2mm}

\today
\end{center}

\begin{abstract} %TODO actualizar resumen y texto con resumen.
La clasificación de estrellas de acuerdo a las variaciones de su brillo es una de las actividades astronómicas más importantes desde finales del siglo XIX.
Esta ha llevado a la detección de estrellas binarias, al mejoramiento de la escala de distancias, y a fuertes avances en astrofísica estelar.
Por lo anterior, existen numerosos proyectos recolectando datos, en cantidades cada vez más grandes, con el fin de encontrar y clasificar estrellas variables.
Los métodos tradicionales de búsqueda de estas estrellas se vuelven ineficientes ante ese tamaño de datos. Entonces, es necesaria la exploración de diferentes técnicas para automatizar la búsqueda y tener una clasificación fiable las estrellas variables.

En este proyecto se busca entrenar un clasificador de estrellas variables que reciba series de tiempo y devuelva candidatos a estrellas variables.
Se procesarán datos públicos del proyecto Araucaria de la galaxia NGC 55, NGC247 y NGC7793  para obtener series de tiempo y utilizar el clasificador sobre ellas.
Se reducirán observaciones en los filtros B y V para 25 a 30 épocas tomadas con el instrumento Wide Field Imager del telescopio MPG/ESO en La Silla.
Se hará fotometría PSF y crossmatch de las observaciones utilizando la suite de software astronómico DAO de Peter Stetson, y se obtendrán series de tiempo.
Posteriormente, se usará el clasificador ya entrenado sobre las series y se generará un catálogo de estrellas candidatas.
Por último, se revisarán las candidatas y se reportarán las estrellas variables.
El objetivo final del proyecto es generar catálogos de estrellas variables en cada galaxia.

Como muestra de entrenamiento se utilizará las series de tiempo del proyecto OGLE (Optical Gravitational Lensing Experiment).
Para el clasificador se usarán algoritmos de vanguardia como: Random forest, Gradient boosted forest y diferentes arquitecturas de redes neuronales, entre otros.
El código se escribirá principalmente en Python 3 haciendo uso de librerías libres como Numpy, Scikit-learn, Astropy, etc. 
Dado el alto volumen de datos, se usará el Cluster de cómputo de alto rendimiento de la Facultad de Ciencias.
\end{abstract}

\normalsize
\newpage
\pagestyle{fancy}
\fancyhead{}
\section{Introducción}

%Introducción a la propuesta de Monografía. Debe incluir un breve resumen del estado del arte del problema a tratar. También deben aparecer citadas todas las referencias de la bibliografía (a menos de que se citen más adelante, en los objetivos o metodología, por ejemplo)

La clasificación de estrellas de acuerdo a sus propiedades ópticas ha sido una de las tareas más útiles de la astronomía y astrofísica moderna.
El proceso permite segregar estrellas y luego estudiar los mecanismos propios de cada categoría de forma independiente.
Por ejemplo, las primeras estrellas variables se registraron durante el siglo XV, pero no fue sino hasta principios del siglo XX que se clasificó sus curvas de luz y se estudiaron las propiedades de las diferentes clases; en particular, esto llevó al descubrimiento de la relación periodo-luminosidad en las variables Cefeidas \cite{1908AnHar..60...87L} y la formulación del mecanismo $\kappa$.

Adicionalmente, usando la relación periodo-luminosidad de una población de estrellas Cefeidas se puede medir su distancia a la tierra.
Esto se usa de la mano con calibraciones basadas en paralaje estelar para calcular distancias a galaxias cercanas y es parte fundamental de la escala de distancias.
Por lo anterior, todas las mediciones que impliquen distancias mayores a 10 Mpc dependen fuertemente del cálculo de distancias usando variables Cefeidas, en particular, el parámetro de Hubble.
Así, se vuelve esencial el mejoramiento de la precisión en la escala de distancias.
En este contexto, nace el \tqt{Araucaria Project}.

El Proyecto Araucaria es una colaboración iniciada en el año 2000 entre astrónomos de instituciones chilenas, estadounidenses y europeas; con el fin de mejorar la precisión de la escala de distancias.
El proyecto hizo seguimiento durante al menos un año y medio a diferentes galaxias cercanas con el fin de generar curvas de luz de sus poblaciones estelares, y usar las curvas para el cálculo de distancia.
Para el cálculo final de la distancia se usó diferentes métodos dependiendo de las poblaciones obtenidas; en particular, si se encontró una población de estrellas Cefeidas, se usó el método de relación periodo-luminosidad.
Adicionalmente, un año después de cada toma de datos, estos se publican en el catálogo de ESO para uso de parte de la comunidad astronómica internacional.

Junto al proyecto Araucaria, está el proyecto OGLE (Optical Gravitational Lensing Experiment) \cite{1992AcA....42..253U}. OGLE busca encontrar evidencia de materia oscura a partir de su efecto de microlente gravitacional sobre estrelals de fondo. Para ello, construyeron en 1997 el telescopio de 1.3-m de Varsovia en el observatorio \tqt{Las Campanas} en Chile \cite{1997AcA....47..319U}; y desde entonces han mantenido un monitoreo fotométrico constante.
Entre los resultados del proyecto se encuentra un catálogos de estrellas variables con sus correspondientes curvas de luz.

Paralelamente, en los años noventa resurge el Machine Learning (aprendizaje de máquinas) como principal línea de investigación dentro de la Inteligencia Artificial, lo que llevó a un rápido avance en algoritmos y técnicas.
Sin embargo, los análisis de los proyectos mencionados anteriormente hacen uso de métodos más tradicionales de la astronomía para la búsqueda de estrellas variables, y no de los novedosos algoritmos de su época.
Con todo lo anterior, se vuelve interesante implementar un clasificador de estrellas variables usando algoritmos de Machine learning, entrenar el clasificador usando el catálogo de estrellas variables de OGLE, y utilizar el clasificador para encontrar estrellas variables en los datos públicos del proyecto Araucaria.%utilizar los datos públicos del Proyecto Araucaria para generar curvas de luz, luego usar los datos de OGLE para entrenar un clasifica

%las curvas de luz clasificadas de OGLE para entrenar un algoritmo capaz de segregar curvas de luz

%generó curvas de luz para las poblaciones estelares; y calculó distancias a partir de las curvas de luz clasificadas.

%Entre los grandes avances, se propone el método de Random Forest en 1995 \cite{598994}, y las redes neuronales recurrentes con Long Short Term Memory


\subsection*{Estado del arte}
Los estudios fotométricos de las galaxias de interés se pueden rastrear a finales de los años 30 para NGC7793 \cite{1938BHarO.907....6S}, a inicios de los sesenta para NGC55 \cite{1961ApJ...133..405D, 1966AuJPh..19..111R}, y finales de los años setenta para NGC247 \cite{1978ApJ...224..710D, 1979ApJ...227..729D, 1980ApJ...239..783D}.
Desde entonces hasta los años noventa se caracterizó su composición química, distancia, perfil de luminosidad, perfil cinemático, metalicidad, regiones de formación estelar y hasta polvo intergaláctico \cite{1982ApJ...253L..73G, 1985ApJS...58..107C,1987ApJ...323...79P,  1990AJ....100..641C, 1995AAS...187.4809W, 1997IrAJ...24...45Z, 1998ApJ...496...39Z} %No aglomerar las referencias. También incluir leyes de extinsión de Cardelli - Schlegell ver NED-IPAC


El Proyecto Araucaria empieza a operar en el año 2000 y publica sus primeros resultados sobre las galaxias de interés durante la misma década.
El Proyecto encontró variables Cefeidas en las tres galaxias y calculó su distancia usando la relación Periodo-Luminosidad \cite{2006AJ....132.2556P, 2008AJ....136.1770G,2010AJ....140.1475P}.
Además, ha realizado seguimientos en infrarrojo para obtener mediciones de distancia con precisión del 1$\%$ \cite{2008ApJ...672..266G, 2009ApJ...700.1141G,2017ApJ...847...88Z}.

Por otro lado, el proyecto OGLE ha publicado catálogos de estrellas variables para las nubes de Magallanes \cite{2015AcA....65..233S,2015AcA....65..297S,2016AcA....66..131S, 2016AcA....66..421P}, el bulbo galáctico \cite{2014AcA....64..177S, 2016AcA....66..405S}, y otras regiones de la Vía Láctea \cite{2008AcA....58...69U, 2015AcA....65....1U}.
Los catálogos se encuentran disponibles bajo el catálogo general \tqt{OGLE Collection of Variable Stars}\footnote{Disponible en \url{http://ogledb.astrouw.edu.pl/~ogle/OCVS/} .}.

Sumado a esto, la detección de estrellas variables se hace tradicionalmente estudiando la tendencia de la curva desviación-magnitud de la población para generar una lista más reducida de estrellas candidatas.
Luego, estudiar las curvas de luz y los periodogramas de tales candidatas y clasificarlas \cite{alejandroThesis}.

Sin embargo, desde los noventa y en particular en la última década se han trabajado nuevas técnicas de clasificación haciendo uso de métodos de Machine Learning para sistematizar la búsqueda y mejorar los resultados en la selección de estrellas candidatas  \cite{1995AAS...187.8805N,2006ApJ...650..497B}.
La metodología usual durante principios de la década fue proyectar las curvas de luz en un espacio de características, y alimentar los algoritmos con las proyecciones.
Las características deben ser seleccionadas de forma inteligente para conservar la información importante y descartar la superflua (como número de puntos en la curva de luz) \cite{2011ApJ...733...10R, 2017A&A...605A.123P, 2018MNRAS.475.2326P}.
Los algoritmos utilizados fueron principalmente regresiones logísticas, Random Forest, k-vecinos más cercanos y Support Vector Machine.
No obstante, se han desarrollado metodologías alternativas tales como: en vez de proyectar las curvas de luz en el espacio de parámetros, usar la curva completa y métodos basados en redes neuronales para la clasificación \cite{2018NatAs...2..151N}; o utilizar un esquema de meta-clasificación para evitar problemas de grano fino y mejorar el recall del clasificador, para luego clasificar los elementos de la meta-clase en las categorías finales \cite{2016ApJ...819...18P}.


%TODO: aquí irían todas las citas a los papers del proyecto araucaria en las galaxias de interés, las citas al proyecto OGLE en sus catálogos de estrellas variables y proceso de clasificación, y también las citas a los papers de clasificación estelar con y sin Machine Learning.





\section{Marco Teórico}

A continuación se presenta brevemente los conocimientos necesarios para el desarrollo del proyecto.

\subsection{El Proyecto Araucaria}

Nace en el año 2000 con el objetivo de mejorar la calibración de la escala de distancia en el universo local, a través del 
Esto principalmente a través de estudiar y caracterizar los efectos de la edad y la metalicidad en la determinación de distancias usando poblaciones estelares \cite{2006MmSAI..77..239P}.

El proyecto hace uso del telescopio de Varsovia de 1.3 m en el Observatorio de Las Campanas (LCO) y el telescopio de 2.2 m MPG/ESO en el Observatorio de la Silla.
Ambos telescopios cuentan cámaras de campo amplio.

Procedimentalmente, el proyecto observa durante largos periodos de tiempo a galaxias del Grupo Local y el Grupo del Escultor.
Las imágenes se toman principalmente en los filtros V e I, pero también hay noches con imágenes en los filtros B y R.
Para el cálculo de distancia el proyecto utiliza diferentes métodos como la relación periodo-luminosidad de las variables Cefeidas, tip of the red giant branch, red clump, y binarias eclipsantes.
Por último, las galaxias estudiadas hasta ahora son: LMC, SMC, Carina, Fornax, Sculptor, IC1613, M33, M81, NGC55, NGC247, NGC300, NGC3109, NGC6822, NGC7793, WLM.



\subsection{Generación de curvas de luz}
Las imágenes a utilizar fueron tomadas con el instrumento Wide Field Imager (WFI) montado en el telescopio MPG/ESO de 2.2 m.
La cámara es un mosaico de 4x2 CCDs cada una con una resolución de 2k por 4k.
Debido al espacio entre chips, se tomó cinco imágenes seguidas por observación en cada filtro cambiando un poco la posición del telescopio, de forma que se puede llenar el espacio entre las CCDs.
Este proceso se conoce como \tqt{dithering}.
Para juntar las cinco imágenes de cada noche y realizar la calibración de Flat y Bias se puede utilizar los paquetes de IRAF: ESOWFI y MSCRED, diseñados específicamente para procesar imágenes de campo amplio como las del instrumento WFI.

Para hacer fotometría de campo denso se utiliza fotometría PSF. En particular, se puede usar el software astronómico DAOPHOT de Peter Stetson \cite{1987PASP...99..191S} para todas las etapas del proceso.
Además, para generar las curvas de luz es necesario identificar las estrellas entre las diferentes observaciones.
Este proceso se conoce como crossmatch.
Una de las aproximaciones al problema es encontrar la transformación de coordenadas entre cada observación con una imagen de referencia, y luego generar catálogos de magnitud contra tiempo de las estrellas que (hasta cierta precisión) ocupen la misma posición.
Esto se hace tradicionalmente con los programas DAOMATCH y DAOMASTER, obteniendose como producto final un archivo con las curvas de luz de todas las estrellas detectadas.
Esas curvas de luz son las que permitirán detectar variabilidad.
Por lo tanto, es esencial obtener el mayor número de estrellas correctamente asociadas entre imágenes, pues de ahí depende la calidad de las curvas de luz y de la búsqueda de estrellas variables.

\subsection{Clasificación usando Machine Learning}
Machine Learning (ML) nació en los años cincuenta como una rama de la inteligencia artificial profundamente relacionada con la estadística y se refiere a la creación de modelos utilizables por una máquina para predicción o clasificación a partir de un conjunto de datos.
Desde los años noventa tomó su propia dirección como ciencia propia gracias al mejoramiento de los algoritmos, el rápido crecimiento de los conjuntos de datos y el mejoramiento de los computadores.
El uso de algoritmos y técnicas de ML en la astronomía comenzó tan temprano como 1990 \cite{1993VA.....36..141M} con redes neuronales artificiales.

La metodología estándar para trabajar con curvas de luz es crear un espacio de parámetros en el cual proyectar las curvas y alimentar los algoritmos con los datos proyectados en tal parámetros.
Esto debido a la irregularidad del muestreo en curvas de luz, pues las condiciones ambientales son muy erráticas.
El espacio de parámetros puede estar compuesto por muchos parámetros con alta correlación entre sí \cite{2018MNRAS.475.2326P}, o por pocos parámetros de naturaleza robusta para dar cuenta del comportamiento global de los datos \cite{2017A&A...605A.123P}




TODO: hablar brevemente de los algoritmos a usar: Random Forest, redes neuronales, redes LSTM.
Hablar del espacio de features y estadistica robusta.

\section{Objetivo general}

Crear catálogos de estrellas variables para las galaxias NGC55, NGC247 y NGC7793 con las observaciones del proyecto Araucaria, y utilizando algoritmos de Machine Learning para la búsqueda y clasificación estelar.




\section{Objetivos específicos}

%Objetivos específicos del trabajo. Empiezan con un verbo en infinitivo.

\begin{itemize}
	\item Realizar fotometría PSF usando los datos públicos de las galaxias del proyecto Araucaria NGC55, NGC247 y NGC7793, con el fin de generar series de tiempo.
	\item Definir un espacio de características significativas de las curvas de luz, y proyectar las curvas en este espacio.
	\item Diseñar y entrenar un clasificador de estrellas variables utilizando como muestra de entrenamiento el catálogo de series de tiempo del proyecto OGLE (Optical Gravitational Lensing Experiment); y métodos como Random Forest, Support Vector Machine, y diferentes arquitecturas de redes neuronales.
	\item A partir del clasificador, generar un catálogo de estrellas variables con los datos del Proyecto Araucaria.
	\item Reencontrar las variables Cefeidas previamente reportadas para estas galaxias.
	\item Generar un catálogo final de estrellas variables para las tres galaxias.
	\item Generar los diagramas magnitud-color y color-color para todas las estrellas detectadas en las galaxias, así como relación periodo-luminosidad de las variables Cefeidas.
\end{itemize}

\section{Metodología}

%Exponer DETALLADAMENTE la metodología que se usará en la Monografía. 
El proyecto es principalmente computacional.
Se requiere el uso del Cluster de cómputo de alto rendimiento tanto para la reducción de datos, como para entrenar el clasificador.
A continuación se presentan los requerimientos del proyecto.

El principal costo computacional viene del almacenamiento de los datos a utilizar.
Se espera tener datos para al menos veintiocho noches y tres galaxias.
El proyecto toma imágenes en los filtros B, V, R e I.
El total de las imágenes ciencia para una galaxia ocupa alrededor de 40 Gigabytes.
Al incluir las imágenes para la corrección de Bias y Flat, se estima unos 70 Gigabytes.
Adicionalmente, durante la reducción se crean archivos temporales de tamaño considerable, por lo que se requiere espacio extra disponible.
Por último, para entrenar el clasificador se utilizaran los datos del proyecto OGLE, que pesan menos de 10 Gigabytes.
En total, se estima un requisito total de almacenamiento de 400 Gigabytes.


Una vez decidida la galaxia, se descargaran todas las observaciones del Proyecto en los diferentes filtros.
Posteriormente, se realizaran las calibraciones usando el software astronómico IRAF \cite{Tody86theiraf}, en particular las tareas ESOWFI y MSCRED, pues fueron escritas y optimizadas para este tipo de datos.
El proceso de crossmatch se hará con los programas DAOMATCH y DAOMASTER de Peter Stetson.
Adicionalmente, se explorará la posibilidad de usar STILTS \cite{2006ASPC..351..666T} y se compará resultados.

Los algoritmos se escribirán en Python usando librerías de alta eficiencia y optimización como Pytorch, Scikit-learn, Numpy, entre otras. 
El entrenamiento del clasificador se hará en paralelo usando multiples CPUs y cuando sea posible, multiples GPUs. 
Para el entrenamiento paralelo en GPUs se utilizará Nvidia CUDA.

Los requisitos de memoria no son tan rígidos porque se puede entrenar el clasificador usando \tqt{batches} de datos en vez de la muestra completa; y la reducción de imágenes astronómicas está optimizada para usar poca memoria, pues los programas a usar fueron escritos cuando la memoria RAM disponible era ordenes de magnitud menor.
Por lo tanto, los cuatro Gigabytes de memoria por CPU y GPU del Cluster es suficiente.



%Monografía teórica o computacional: ¿Cómo se harán los cálculos teóricos? ¿Cómo se harán las simulaciones? ¿Qué requerimientos computacionales se necesitan? ¿Qué espacios físicos o virtuales se van a utilizar?

%Monografía experimental: Recordar que para ser aprobada, los aparatos e insumos experimentales que se usarán en la Monografía deben estar previamente disponibles en la Universidad, o garantizar su disponibilidad para el tiempo en el que se realizará la misma. ¿Qué montajes experimentales se van a usar y que material se requiere? ¿En qué espacio físico se llevarán a cabo los experimentos? Si se usan aparatos externos, ¿qué permisos se necesitan? Si hay que realizar pagos a terceros, ¿cómo se financiará esto?


\section{Cronograma}
A continuación se presenta el cronograma del proyecto.
Los periodos tienen una duración de dos semanas cada uno.
Dado que se debe entregar la primera versión del documento final en la semana 11 del segundo semestre de ejecución del proyecto, se diseñó el cronograma con 13 periodos, o 26 semanas.


\begin{table}[htb]
	\begin{tabular}{|c|cccccccccccccc| }
	\hline
	Tareas $\backslash$ Periodo & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 &  \\
	\hline
	1 & X & X & X &  X &  X &  X & X  & X &  &   &   &   &     & \\
	2 & X & X & X & X  &   &   &   &  &  &   &   &   &     & \\	
	3 &  &  &  & X & X  & X  &  X &  &  &   &   &   &      &\\
	4 &  &  &  &   & X & X  & X  & X & X &   &   &   &      &\\
	5 & X & X & X & X & X  &  X & X  &  &  &   &   &   &     & \\
	6 & X & X &  & X  & X & X  & X  &  &  &   &   &   &      &\\
	7 &  &  & X &  X & X  & X  & X  & X & X & X  &   &   &   &   \\
	8 &  &  &  &   &   &  X &  X & X & X &  X &   &   &      &\\
	9 &  &  &  &   &   &   &   & X & X & X  & X  & X  & X    & \\
	10 &  &  &  &   &   &   & X  & X &  &   &  X &  X &   X  & \\ 
	11 & X & X & X & X  & X  & X  &  X & X & X & X  & X  & X  &  X &\\   \hline
	\end{tabular}
\end{table}
\vspace{1mm}


\begin{itemize}
	\item Tarea 1: revisión bibliográfica.
	\item Tarea 2: descargar las galaxias del repositorio público de ESO correspondientes al proyecto Araucaria, así como las imágenes de calibración y realizar el correspondiente procesamiento.
	\item Tarea 3: realizar fotometría PSF sobre las imágenes procesadas y obtener catálogos de magnitud y coordenadas.
	\item Tarea 4: realizar el cross-matching de las estrellas en los catálogos de fotometría para obtener las series de tiempo.
	\item Tarea 5: definir un espacio de características en el que se pueda proyectar las curvas de luz reteniendo la mayor cantidad de información para la implementación del método supervisado.
	\item Tarea 6: construir la muestra de entrenamiento con las estrellas clasificadas del proyecto OGLE y proyectarlas al espacio de características.
	\item Tarea 7: diseñar un clasificador usando algoritmos de Machine Learning y explorar el espacio de hiperparámetros para optimizar los resultados.
	\item Tarea 8: usar el clasificador sobre las curvas de luz generadas y formar un catálogo de estrellas candidatas. 
	\item Tarea 9: Inspeccionar las estrellas candidatas,  determinar periodos, y reportar el catálogo final de estrellas variables.
	\item Tarea 10: preparar presentaciones del proyecto.
	\item Tarea 11: escribir el documento.
	
\end{itemize}


\section{Personas Conocedoras del Tema}

%Nombres de por lo menos 3 profesores que conozcan del tema. Uno de ellos debe ser profesor de planta de la Universidad de los Andes.

\begin{itemize}
	\item Dra. Beatriz Sabogal (Universidad de los Andes)
	\item Dr. Ronnald Mennickent (Universidad de Concepción, Chile)
	\item Dr. Grzegorz Pietrzy{\'n}sky (Instituto Copérnico, Polonia)	
	\item Dr. Igor Soszy\'nski (Universidad de Varsovia, Polonia)
\end{itemize}



\section{Consideraciones éticas}
Todos los datos que se planea usar son públicos y se encuentran disponibles en el catálogo del Observatorio Europeo Austral (ESO, por sus siglas en inglés).
Todo el software utilizado para el desarrollo del proyecto es software Libre.
No se modificará ninguna muestra de datos.
En caso de hacer uso de algoritmos ya propuestos, se incluirá la debida referencia y citación en el documento final.



%\selectlanguage{english}
%\bibliography{mybib}
%\bibliographystyle{unsrt}

\printbibliography{}

\section*{ }

\rule{5.3cm}{0.01cm} \hfill \rule{6.3cm}{0.01cm}


Dr. Alejandro García \hfill \hspace*{0mm}\phantom{Firma: }Javier Alejandro Acevedo Barroso

Director. \hspace{6.92cm} Estudiante 201422995

\end{document} 